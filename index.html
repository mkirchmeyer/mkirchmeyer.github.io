<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Matthieu Kirchmeyer</title>

  <meta name="author" content="Matthieu Kirchmeyer">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Matthieu Kirchmeyer</name>
              </p>
              <p>
                I am a final-year PhD student at <a href="https://mlia.lip6.fr" target="_blank"> Sorbonne Universit√©</a> (graduating in spring 2023) advised by <a href="https://scholar.google.com/citations?user=rFaxB20AAAAJ&hl=en" target="_blank"> Patrick Gallinari </a> and <a href="https://scholar.google.fr/citations?hl=en&user=INHspc0AAAAJ&view_op=list_works&sortby=pubdate" target="_blank"> Alain Rakotomamonjy</a>.
                I am also a researcher at <a href="https://ailab.criteo.com" target="_blank">Criteo AI Lab</a>.
              </p>
              <p>
                I develop deep learning models which generalize and adapt to out-of-distribution data for dynamics forecasting and classification problems.
              </p>

              </p>
                I obtained my Master's degree at <a href="https://www.minesparis.psl.eu" target="_blank">Mines Paris - PSL</a> and at Ecole Normale Sup√©rieure Paris Saclay (<a href="https://www.master-mva.com" target="_blank">Master MVA</a>).
              </p>
              <p style="text-align:center">
                <a href="mailto:matthieu.kirchmeyer@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=oJkKtrkAAAAJ&hl=en" target="_blank">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/m_kirchmeyer" target="_blank">Twitter</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/matthieukirchmeyer/" target="_blank">LinkedIn</a> &nbsp/&nbsp
                <a href="https://github.com/mkirchmeyer" target="_blank"> GitHub </a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img src="images/photo.png" width="180" style="border-radius:50%" class="profile-image">
            </td>
          </tr>
        </tbody>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                <ul><li style="list-style-position:inside;margin:0;padding:0;text-align:left;">01/2023: Spotlight paper (notable-top-25%) @ ICLR2023. </li>
                </ul>
              </p>
              <p>
                <ul><li style="list-style-position:inside;margin:0;padding:0;text-align:left;">10/2022: Paper @ NeurIPS 2022 and NeurIPS AI4Science 2022 workshop. </li>
                </ul>
              </p>
              <p>
                <ul><li style="list-style-position:inside;margin:0;padding:0;text-align:left;">07/2022: Paper @ ICML 2022 and ICML PODS 2022 workshop. </li>
                </ul>
              </p>
              <p>
                <ul><li style="list-style-position:inside;margin:0;padding:0;text-align:left;">04/2022: Paper @ ICLR 2022 and I am highlighted reviewer ! </li>
                </ul>
              </p>
              <p>
                <ul><li style="list-style-position:inside;margin:0;padding:0;text-align:left;">04/2022: We are organizing a challenge on domain generalization for computational advertising at ECML-PKDD 2022. <a href="https://codalab.lisn.upsaclay.fr/competitions/3353" target="_blank"> Check it out</a> ! </li>
                </ul>
              </p>
            </td>
          </tr>
        </tbody>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Publications</heading>
              </td>
            </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/dino_gif.gif" alt="PontTuset" width="300" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Continuous PDE Dynamics Forecasting with Implicit Neural Representations</papertitle>
              <br>
              Y. Yin*,
              <strong>M. Kirchmeyer*</strong>,
              J-Y. Franceschi*,
              A. Rakotomamonjy,
              P. Gallinari (*equal contribution)
              <br>
              <i><strong>ICLR 2023 - Spotlight</strong> (notable-top-25%). Preliminary version at <strong>NeurIPS 2022 AI4Science Workshop</strong>.</i>
              <br>
              <a href="https://arxiv.org/abs/2209.14855", target="_blank">arXiv</a> /
              <a href="https://openreview.net/forum?id=B73niNjbPs", target="_blank">OpenReview</a> /
              <a href="https://github.com/mkirchmeyer/DINo", target="_blank">code</a> /
              <p></p>
              <p></p>
              <p>
                We propose DINo, a novel continuous-time continuous-space neural PDE forecaster with extensive spatiotemporal extrapolation capabilities including generalization to unseen free-form sparse meshes and resolutions.
                DINo combines a neural ODE model with Implicit Neural Representations (INRs).
                Check out our videos on our <a href="https://github.com/mkirchmeyer/DINo", target="_blank">github page</a> !
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/diwa.png" alt="PontTuset" width="300" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Diverse Weight Averaging for Out-of-Distribution Generalization</papertitle>
              <br>
              A. Ram√©*,
              <strong>M. Kirchmeyer*</strong>,
              T. Rahier,
              A. Rakotomamonjy,
              P. Gallinari,
              M. Cord (*equal contribution)
              <br>
              <i><strong>NeurIPS 2022</strong>. Preliminary version at <strong>ICML 2022 PODS Workshop</strong></i>
              <br>
              <a href="https://arxiv.org/abs/2205.09739", target="_blank">arXiv</a> /
              <a href="https://openreview.net/forum?id=tq_J_MqB3UB", target="_blank">OpenReview</a> /
              <a href="https://github.com/alexrame/diwa", target="_blank">code</a> /
              <a class="btn btn-primary btn-outline my-1 mr-1 btn-sm" href="/publication/diwa/slides.pdf" target="_blank" rel="noopener"> slides</a> /
              <a class="btn btn-primary btn-outline my-1 mr-1 btn-sm" href="/publication/diwa/poster.pdf" target="_blank" rel="noopener"> poster</a>
              <p></p>
              <p></p>
              <p>
                DiWA is a new weight averaging method for OOD generalization, which introduces diversity. It is state-of-the-art on the challenging DomainBed benchmark against recent OOD methods without additional inference overhead. DiWA is backed theoretically by a bias-variance decomposition of weight averaging.
              </p>
            </td>
          </tr>

        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/CoDA.gif" alt="PontTuset" width="300" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Generalizing to New Physical Systems via Context-Informed Dynamics Model</papertitle>
              <br>
              <strong>M. Kirchmeyer*</strong>,
              Y. Yin*,
              J. Don√†,
              N. Baskiotis,
              A. Rakotomamonjy,
              P. Gallinari (*equal contribution)
              <br>
              <i><strong>ICML 2022</strong></i>
              <br>
              <a href="https://arxiv.org/abs/2202.01889", target="_blank">arXiv</a> /
              <a href="https://proceedings.mlr.press/v162/kirchmeyer22a.html", target="_blank">PMLR</a> /
              <a href="https://github.com/yuan-yin/CoDA", target="_blank">code</a> /
              <a class="btn btn-primary btn-outline my-1 mr-1 btn-sm" href="/publication/coda/slides.pdf" target="_blank" rel="noopener"> slides</a> /
              <a class="btn btn-primary btn-outline my-1 mr-1 btn-sm" href="/publication/coda/poster.pdf" target="_blank" rel="noopener"> poster</a> /
              <a href="https://icml.cc/virtual/2022/poster/18049", target="_blank">video</a>
              <p></p>
              <p></p>
              <p>
                We propose CoDA a new context-informed framework based on hypernetworks to adapt fast, parameter and sample-efficiently neural forecasters to new PDEs and ODEs parameters, thereby limiting the retraining cost on new systems.
              </p>
            </td>
          </tr>

        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ostar.png" alt="PontTuset" width="300" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Mapping conditional distributions for domain adaptation under generalized target shift</papertitle>
              <br>
              <strong>M. Kirchmeyer</strong>,
              A. Rakotomamonjy,
              E. de B√©zenac,
              P. Gallinari
              <br>
              <i><strong>ICLR 2022</strong>. Also presented at <a href="https://caprfiap2022.sciencesconf.org" target="_blank"> CAp </a> 2022 (oral)</i>
              <br>
              <a href="https://arxiv.org/abs/2110.15057", target="_blank">arXiv</a> /
              <a href="https://openreview.net/forum?id=sPfB2PI87BZ", target="_blank">OpenReview</a> /
              <a href="https://github.com/mkirchmeyer/ostar", target="_blank">code</a> /
              <a class="btn btn-primary btn-outline my-1 mr-1 btn-sm" href="/publication/ostar/slides.pdf" target="_blank" rel="noopener"> slides</a> /
              <a class="btn btn-primary btn-outline my-1 mr-1 btn-sm" href="/publication/ostar/poster.pdf" target="_blank" rel="noopener"> poster</a> /
              <a href="https://iclr.cc/virtual/2022/poster/6951", target="_blank"> video</a>
              <p></p>
              <p></p>
              <p>
                We propose OSTAR a new deep learning method to align pretrained representations under unsupervised domain adaptation with both conditional and label shift.
                OSTAR introduces useful regularization biases in NNs with Optimal Transport.
              </p>
            </td>
          </tr>
        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/imput.png" alt="PontTuset" width="300" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Unsupervised domain adaptation with non-stochastic missing data</papertitle>
              <br>
              <strong>M. Kirchmeyer</strong>,
              P. Gallinari,
              A. Rakotomamonjy,
              A. Mantrach
              <br>
              <i><strong>ECML-PKDD 2021</strong> - Data Mining and Knowledge Discovery journal.</i>
              <br>
              <a href="https://arxiv.org/abs/2109.09505", target="_blank">arXiv</a> /
              <a href="https://link.springer.com/article/10.1007/s10618-021-00775-3", target="_blank">journal link</a> /
              <a href="https://link.springer.com/epdf/10.1007/s10618-021-00775-3?sharing_token=gqssT5CZwXvj5CRTg_kAYPe4RwlQNchNByi7wbcMAY5Ib3lDoPW2Dr47hpbARxMYmjA0t2Gw9UBEnr7uW3gHiRTgrHGLqf3yMGEK5y-uCea22zZivXSTGN5BRkX_K_mUSccHovu4lCF3hkPH4yBKkdMFHgMdNdWOPW9QMyxMDiM%3D", target="_blank">pdf</a> /
              <a href="https://github.com/mkirchmeyer/adaptation-imputation", target="_blank">code</a> /
              <a class="btn btn-primary btn-outline my-1 mr-1 btn-sm" href="/publication/adapt-imput/slides.pdf" target="_blank" rel="noopener"> slides</a>
              <p></p>
              <p></p>
              <p>
                We propose a new deep learning model to impute non-stochastic missing data, as seen in cold-start problems in recommender systems or imputation problems in computer vision. It performs unsupervised domain adaptation by leveraging supervision from a fully observed domain.
              </p>
            </td>
          </tr>

        </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Older</heading>
              </td>
            </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/robotic4.png" alt="PontTuset" width="250" style="border-style:none">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Conformal Robotic Stereolithography</papertitle>
              <br>
              A. Stevens*, R. Oliver*, <strong>M. Kirchmeyer</strong>, J. Wu, L. Chin, E. Polsen, C. Archer, C. Boyle, J. Garber and J. Hart (*equal contribution)
              <br>
              <i><strong>3D Printing and Additive Manufacturing</strong> journal, 2016.</i>
              <br>
              <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5363219/", target="_blank">journal link</a>
              <p></p>
              <p></p>
              <p>
                We present a robotic system that is capable of maskless layerwise photopolymerization on curved surfaces.

                This paper on robotic 3D printing was done as part of a 5-month internship in the <a href="https://mechanosynthesis.mit.edu" target="_blank"> Mechanosynthesis Group</a> in the Mechanical Engineering department at MIT.
              </p>
            </td>
          </tr>
        </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
              Template modified from <a href="https://jonbarron.info/" target="_blank">here </a></p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>